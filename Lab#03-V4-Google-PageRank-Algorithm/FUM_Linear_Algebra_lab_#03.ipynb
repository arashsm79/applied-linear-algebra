{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evL0CGnUltdc"
      },
      "source": [
        "# Applied Linear Algebra - Lab 3\n",
        "    Ferdowsi University of Mashhad - Department of Computer Engineering\n",
        "\n",
        "***Winter 2024***\n",
        "> #### ***If you've any question, feel free to ask:*** $$@Maresha82$$\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "* [Determinant](#determinant)\n",
        "    * [Exercise1](#exercise-1)\n",
        "        * [Test](#test-your-function) $\\checkmark$\n",
        "    \n",
        "* [Cramer's rule](#cramers-rule)\n",
        "    * [Exercise2](#exercise-2)\n",
        "        * [Test](#show-time)$\\checkmark$\n",
        "        * [Exercise 2.1](#exercise-21)\n",
        "* [Eigen value and eigen vector](#eigen-value-and-eigen-vector)\n",
        "    * [Von Mises](#von-mises-iteration-algorithm)\n",
        "        * [Exercise 3](#exercise-3)\n",
        "            * [Exercise 3.1](#exercise-31)\n",
        "            * [Exercise 3.2](#exercise-32)\n",
        "            * [Exercise 3.3](#exercise-33)\n",
        "            * [Exercise 3.4](#exercise-34)\n",
        "            * [Exercise 3.5](#exercise-35)\n",
        "            * [Exercise 3.6](#exercise-36)\n",
        "        * [Test](#show-time)$\\checkmark$\n",
        "* [Markov chain](#markov-chain)\n",
        "    * [What is Markov Chain?!](#now-what-is-markov-chain)\n",
        "        * [Properties of markov chain](#now-what-is-markov-chain)\n",
        "        * [Exercise 4](#exercise-4)\n",
        "    * [Population problem](#population-problem)\n",
        "        * [Exercise 4.1](#exercise-41)\n",
        "        * [Exercise 4.2](#exercise-42)\n",
        "    * [Predicting distant future](#predicting-distant-future)\n",
        "        * [Exercise 4.3](#exercise-43)\n",
        "        * [Exercise 4.4](#exercise-44)\n",
        "    * [Steady state vectors](#steady-state-vectors)\n",
        "        * [Someone said eigenvalue ?!](#someone-said-eigen-value)\n",
        "        * [Exercise 4.5](#exercise-45)\n",
        "            * [Exercise 4.5.1](#exercise-451)\n",
        "            * [Exercise 4.5.2](#exercise-452)\n",
        "    * [Diagnoalization](#diagonalization)\n",
        "        * [Exercise 4.6](#exercise-46)\n",
        "            * [Exercise 4.6.1](#exercise-461)\n",
        "            * [Exercise 4.6.2](#exercise-462)\n",
        "            * [Exercise 4.6.3](#exercise-463)\n",
        "            * [Exercise 4.6.3.1](#exercise-4631)\n",
        "            * [Exercise 4.6.3.2](#exercise-4632)\n",
        "* [Google page rank algorithm](#google-page-rank-algorithm)\n",
        "    * [The insight](#the-insight)\n",
        "    * [Random Walks](#random-walks)\n",
        "        * [Absorbing bounderies](#absorbing-bounderies)\n",
        "        * [Exercise 5.1](#exercise-51)\n",
        "        * [Exercise 5.2](#exercise-52)\n",
        "        * [Exercise 5.3](#exercise-53)\n",
        "    * [Random Walks on undirected graph](#random-walks-on-undirected-graph)\n",
        "        * [Exercise 5.4](#exercise-54)\n",
        "    * [Someone directed graph?!](#someone-said-directed-graph)\n",
        "        * [Exercise 5.5](#exercise-55)\n",
        "    * [Structure of Internet](#structure-of-the-internet)\n",
        "    * [The Real Ones!](#the-real-ones)\n",
        "        * [Exercise 5.6](#exercise-56)\n",
        "        * [Exercise 5.7](#exercise-57)\n",
        "        * [Exercise 5.8](#exercise-58)\n",
        "        * [Exercise 5.9](#exercise-59)\n",
        "        * [Exercise 5.10](#exercis-510)\n",
        "        * [Final Exercise!](#final-exercise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPEOL_6Ll8T8"
      },
      "source": [
        "Welcome to extraordinary applied linear algebra project.    \n",
        "In this project we're going to discover the most sensational parts of applied linear algebra which has a sentimental connection with Reinforcement Learning and other things.    \n",
        "Let's have a look on..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zVSF1NUSyJyG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCDxP-jR8Ej6"
      },
      "source": [
        "## Determinant\n",
        "Since calculating the determinant of a square matrix is a fundamental operation in linear algebra, We must consider to gain those reliable data.  \n",
        "As you may know, you can calculate the determinant of a 2*2 matrix like this:\n",
        "$$\n",
        "\\\n",
        "\\begin{vmatrix}\n",
        "a & b \\\\\n",
        "c & d \\\\\n",
        "\\end{vmatrix}\n",
        "= ad - bc\n",
        "$$\n",
        "\n",
        "And such a similar manner for 3*3:   \n",
        "$$\n",
        "\\ \\begin{vmatrix}\n",
        "a & b & c \\\\\n",
        "d & e & f \\\\\n",
        "g & h & i \\\\\n",
        "\\end{vmatrix}\n",
        "= a(ei - fh) - b(di - fg) + c(dh - eg)\n",
        "$$\n",
        "Now let's calculate the determinant of an arbitrary matrix using numpy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO64xzRw-BeO"
      },
      "source": [
        "### Exercise 1\n",
        "Implement a function to calculate the determinant of a mtrix.   \n",
        "Remember you're not allowed to use built-in functions of any provided libraries such as numpy and etc.(It would be guaranteed that your matrix is an $n*n$ matrix.)\n",
        "\n",
        "<details>\n",
        "    <summary>Hint No.1</summary>\n",
        "    <p>\n",
        "    Highly recommended to implement it using gaussian elimination tactics\n",
        "    <ul>\n",
        "    <li>Use Gaussian elimination to convert the matrix to upper triangular form </li>\n",
        "    <li>Swap rows to get a non-zero diagonal element</li>\n",
        "    <li>If no non-zero element is found, determinant is zero</li>\n",
        "    <li>Eliminate the elements below the diagonal</li>\n",
        "    <li>If no non-zero element is found, determinant is zero</li>\n",
        "</ul>\n",
        "    </p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IBYbX6me9-HW",
        "outputId": "c7556d74-da80-4f5d-9e06-626085628e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determinant: 43.0\n"
          ]
        }
      ],
      "source": [
        "def determinant(matrix):\n",
        "    n = matrix.shape[0]\n",
        "\n",
        "    # Make a copy of the matrix to avoid modifying the original\n",
        "    mat_copy = matrix.astype(float)\n",
        "\n",
        "    for i in range(n):\n",
        "        #TODO\n",
        "        pass\n",
        "\n",
        "    # Multiply the diagonal elements to get the determinant\n",
        "    det = np.prod(np.diagonal(mat_copy))\n",
        "\n",
        "    return det\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-wKaEm6C-9u"
      },
      "source": [
        "#### Test your function\n",
        "As you may know we've some built-in function that can be used in order to calculate the determinant of a matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "X_mlCirfCGiZ"
      },
      "outputs": [],
      "source": [
        "test_matrix = np.array([[4, -2, 1],\n",
        "                         [-2, 5, 3],\n",
        "                         [1, 3, 6]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Jqi-_01zDKZe",
        "outputId": "b7d48bf3-9f9e-47ac-b570-873b2646bc93"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(43.0, 43.0, 43.000004)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensorflow\n",
        "\n",
        "# tensor\n",
        "tf_matrix = tf.constant(test_matrix, dtype=tf.float32)\n",
        "tf_result = tf.linalg.det(tf_matrix).numpy()\n",
        "\n",
        "#Numpy\n",
        "np_result=np.linalg.det(test_matrix)\n",
        "\n",
        "#Your Function\n",
        "det_result = determinant(test_matrix)\n",
        "\n",
        "det_result,np_result,tf_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVKqImmpEb8N"
      },
      "source": [
        "## Cramer's rule   \n",
        "Cramer's Rule is a mathematical technique used to solve a system of linear equations with as many equations as unknowns, provided that the system's coefficient matrix is non-singular (i.e., its determinant is non-zero). It provides a method to find the unique solution for each variable in terms of determinants.   \n",
        "You may know how to use cramer's rule but you can use the matrix that has provided below.\n",
        "$$\n",
        "\\\n",
        "x_1 = \\frac{\\begin{vmatrix} b_1 & a_{12} & a_{13} \\\\ b_2 & a_{22} & a_{23} \\\\ b_3 & a_{32} & a_{33} \\end{vmatrix}}{\\begin{vmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{vmatrix}}\n",
        "\\;\n",
        "x_2 = \\frac{\\begin{vmatrix} a_{11} & b_1 & a_{13} \\\\ a_{21} & b_2 & a_{23} \\\\ a_{31} & b_3 & a_{33} \\end{vmatrix}}{\\begin{vmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{vmatrix}}\\\\\n",
        "x_3 = \\frac{\\begin{vmatrix} a_{11} & a_{12} & b_1 \\\\ a_{21} & a_{22} & b_2 \\\\ a_{31} & a_{32} & b_3 \\end{vmatrix}}{\\begin{vmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{vmatrix}}\n",
        "$$   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFOGzCzHF8mt"
      },
      "source": [
        "### Exercise 2\n",
        "In this exercise we want to calculate the answer of the linear system using cramer's rule.\n",
        "Feel free to use any built-in function in order to calculate the determinant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "8em77f9LGnzy",
        "outputId": "f6e4d4f8-53aa-4ba8-e76d-9ffdd4c5801e"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-c3e20ee27a5d>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    solutions.append(?)\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "def cramer_rule(matrix_A, vector_b):\n",
        "    # Calculate the determinant of the coefficient matrix\n",
        "    # You can also put your function of determinant here.\n",
        "    # det_A = np.linalg.det(matrix_A)\n",
        "    if det_A == 0:\n",
        "        raise ValueError(\"The determinant of the coefficient matrix is zero. Cramer's Rule cannot be applied.\")\n",
        "\n",
        "    n = matrix_A.shape[0]\n",
        "    solutions = []\n",
        "\n",
        "    for i in range(n):\n",
        "        # Create a copy of the coefficient matrix and replace the i-th column with the vector b\n",
        "        matrix_A_i = matrix_A.copy()\n",
        "        # matrix_A_i[:, i] = ?\n",
        "        #TODO\n",
        "          # vector_b\n",
        "        # Calculate the determinant of the modified matrix\n",
        "        det_A_i = np.linalg.det(matrix_A_i)\n",
        "\n",
        "        # Cramer's Rule: x_i = det(A_i) / det(A)\n",
        "        # solution_i = det_A_i / det_A\n",
        "        solutions.append(?)\n",
        "\n",
        "    return solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofo2lUuzS5An"
      },
      "source": [
        "#### Show time!   \n",
        "You can test your code here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KMzTF3YeS4IK"
      },
      "outputs": [],
      "source": [
        "A_matrix = np.array([[2, -1, 3],\n",
        "                     [1, 2, 1],\n",
        "                      [3, 4, 5]], dtype=float)\n",
        "\n",
        "b_vector = np.array([8, 5, 1], dtype=float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2a49iRVGdmkK"
      },
      "outputs": [],
      "source": [
        "#Numpy\n",
        "np_result=np.linalg.solve(A_matrix,b_vector)\n",
        "#Your function\n",
        "you= cramer_rule(A_matrix,b_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e2XYcjXYVVZ"
      },
      "source": [
        "#### Exercise 2.1:\n",
        "Based on what you've learned before,\n",
        "Provide some tensorflow fucntion that can solve our system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "coRjuurWWkda"
      },
      "outputs": [],
      "source": [
        "#Tensorflow\n",
        "# TODO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7TrwZ0cd-B5"
      },
      "source": [
        "## Eigen value and eigen vector\n",
        "Eigenvalues and eigenvectors are fundamental concepts in linear algebra. Let's delve into an explanation.     \n",
        "  \n",
        "\n",
        "In linear algebra, consider a square matrix\n",
        "$A$ .An eigenvector $(\n",
        "v)$ and its corresponding eigenvalue $(λ)$ satisfy the following equation:\n",
        "$$Av=\\lambda v$$  \n",
        "- $A \\rightarrow$ Square matrix\n",
        "- $v \\rightarrow$ eigen vector\n",
        "- $\\lambda \\rightarrow$ eigen value\n",
        "\n",
        "**Eigen vector equation:**   \n",
        "$$(A-\\lambda I)v=0$$   \n",
        "$I$ is identity matrix.   \n",
        "**Eigen value equation:**   \n",
        "$$det(A-\\lambda I)=0$$   \n",
        "This equation yields the eigenvalues $\\lambda_1,\\lambda_2,...,\\lambda_n$ for $n* n$ matrix.  \n",
        "e.g.\n",
        "$$A=\n",
        "\\begin{bmatrix} 4 & -1 \\\\ 2 & 1 \\end{bmatrix}\\\\\n",
        "$$\n",
        "----\n",
        "$$\\text{det}\\left(\\begin{bmatrix} 4-\\lambda & -1 \\\\ 2 & 1-\\lambda \\end{bmatrix}\\right) = 0\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qq-KayMk7rd"
      },
      "source": [
        "### Von Mises Iteration Algorithm:\n",
        "In order to find eigen values and eigen vectors of a matrix, we can use an algorithm named \"***Von Mises Iteration***\".    \n",
        " is an eigenvalue algorithm: given a diagonalizable matrix\n",
        "$A$, the algorithm will produce a number\n",
        "$\\lambda$ , which is the greatest (in absolute value) eigenvalue of\n",
        "\n",
        "$A$, and a nonzero vector\n",
        "$v$, which is a corresponding eigenvector of\n",
        "$\\lambda$ , that is,\n",
        "$$ Av=\\lambda v$$.    \n",
        "\n",
        "This algorithm is also known as Power Iteration algorithm.     \n",
        "\n",
        "Power Iteration is an iterative numerical method used to find the dominant eigenvalue and corresponding eigenvector of a square matrix. The dominant eigenvalue is the one with the **largest magnitude**. The method is particularly useful for large sparse matrices, where direct methods may be computationally expensive.  \n",
        "\n",
        "Here are the key steps involved in the Power Iteration method:\n",
        "1. ***Initialization:***   \n",
        "Start with an initial guess for the eigenvector\n",
        "$v_0$\n",
        " . The choice of\n",
        "$v_0$\n",
        "  is not critical, as long as it is not orthogonal to the eigenvector associated with the dominant eigenvalue.\n",
        "2. ***Iteration:***    \n",
        "Iteratively apply the matrix $A$\n",
        "to the current estimate of the eigenvector\n",
        "$v_k$\n",
        "  and normalize the result:\n",
        "  $$v_{k+1}=\\frac {A_{v_k}} {||A_{v_k}||}$$   \n",
        "  This step ensures that the eigenvector remains a unit vector.\n",
        "\n",
        "3. ***Convergence:***    \n",
        "Repeat the iteration until\n",
        "$v_k$\n",
        "  converges to the dominant eigenvector. The eigenvalue corresponding to this eigenvector is approximated by the [Rayleigh quotient](https://en.wikipedia.org/wiki/Rayleigh_quotient):\n",
        "  $$\\lambda_k=\\frac{(A_{v_k})^Tv_k}{v^T_k v_k}$$  \n",
        "  > **The eigenvalue approximation improves with each iteration.**\n",
        "\n",
        "\n",
        "4. ***Eigenvalue Extraction:***    \n",
        "The dominant eigenvalue is given by the Rayleigh quotient at convergence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWTEl6Wagr4L"
      },
      "source": [
        "### Exercise 3:\n",
        "Now in this section we want to calculate the eigen vectors and eigen values of an arbitrary matrix $A$ based on Von Mises algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "udpGT29BqfTJ"
      },
      "outputs": [],
      "source": [
        "A=np.array([[1,5,4],\n",
        "            [7,5,1],\n",
        "            [6,2,1]])\n",
        "# This is our test matrix. Don't touch it :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og3yeRMSqL3y"
      },
      "source": [
        "#### Exercise 3.1:\n",
        "**Initialization**: Just provide a simple random vector to start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_yxWA6IuqBEW",
        "outputId": "9af18722-6e2a-4fde-e4d7-7c7590de4055"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "v=?\n",
        "# Just a random 1*n vector using numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KwqDN9gre-b"
      },
      "source": [
        "#### Exercise 3.2:\n",
        "***Iteration:***\n",
        "Use a for loop to iterate over iteration number and make it as better as you can."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2_xqrLJWrzlN",
        "outputId": "5537d264-1a7e-48b4-f0e3-9988d4dc8578"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11.0, array([0.5375904, 0.7044288, 0.46344  ]))"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iteration=1000\n",
        "n = A.shape[0]\n",
        "for _ in range(iteration):\n",
        "    pass\n",
        "\n",
        "# Eigenvalue Extraction\n",
        "lambda_dominant = ?\n",
        "\n",
        "lambda_dominant, v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgOvoFzeuAbp"
      },
      "outputs": [],
      "source": [
        "#make it as function:\n",
        "def power_iteration(A, num_iterations=1000):\n",
        "    n = A.shape[0]\n",
        "\n",
        "    # Step 1\n",
        "    for _ in range(num_iterations):\n",
        "        # Step 2\n",
        "        pass\n",
        "    #Eigenvalue Extraction\n",
        "    lambda_dominant =?\n",
        "\n",
        "    return lambda_dominant, v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiRg-D2TuVh9"
      },
      "source": [
        "#### Exercise 3.3:\n",
        "As long as power iteration algorithm only works on diagonalizable matrix, Provide a fucntion to check if it's diagonalizable matrix or not.(feel free to use any built-in function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj013hJku8vx"
      },
      "outputs": [],
      "source": [
        "def diagonal(A): -> bool\n",
        "  pass\n",
        "  # TODO\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aukcvczgvatz"
      },
      "source": [
        "#### Exercise 3.4:    \n",
        "- Explain the relation between the number of eigen values and the rank of the matrix.\n",
        "- Also explain why we need to check whether the matrix is diagonalizable or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBvPr3uFv2kd"
      },
      "source": [
        "> Write down what you want :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRCJcaWrvG50"
      },
      "source": [
        "#### Exercise 3.5:\n",
        "Now as the final step just implement a function to extract all $n$ number of eigen values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ABgZAPkzg2gJ"
      },
      "outputs": [],
      "source": [
        "def eigenvalues(matrix, num_iterations):\n",
        "    n = matrix.shape[0]\n",
        "    eigenvalues_list = []\n",
        "    eigenvectors_list = []\n",
        "\n",
        "    for _ in range(n):\n",
        "        # Use power iteration to find dominant eigenvalue and eigenvector\n",
        "        eigenvalue, eigenvector = power_iteration(matrix, num_iterations)\n",
        "\n",
        "\n",
        "        #TODO\n",
        "\n",
        "\n",
        "        # Deflate the matrix\n",
        "        matrix = matrix - eigenvalue * np.outer(eigenvector, eigenvector)\n",
        "\n",
        "    return eigenvalues_list, eigenvectors_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN08r6DvwauP"
      },
      "source": [
        "##### Show Time!\n",
        "Now we need to check wheter you've implement them successfully or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0RG9R4riwmEj",
        "outputId": "9fe8eefe-633e-467e-febd-efbaa7aed947"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(array([11.        , -5.16227766,  1.16227766]),\n",
              " array([[-0.5375904 , -0.71145239,  0.22224099],\n",
              "        [-0.7044288 ,  0.43581731, -0.60466422],\n",
              "        [-0.46344   ,  0.55127014,  0.76484647]]))"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Your function\n",
        "eigenvalues_result, eigenvectors_result = eigenvalues(A)\n",
        "print(\"Eigenvalues:\", eigenvalues_result)\n",
        "print(\"Eigenvectors:\")\n",
        "for i, eigenvector in enumerate(eigenvectors_result):\n",
        "    print(f\"Eigenvalue {i+1}: {eigenvalues_result[i]}, Eigenvector: {eigenvector}\")\n",
        "\n",
        "#Numpy\n",
        "np.linalg.eig(A)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7mgy8L2w5ZX"
      },
      "source": [
        "#### Exercise 3.6:\n",
        "Now provide a fucntion to calcualte eigen values and eigen vectors using tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqo94bONxBYD"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "#tf.linalg.eig ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq5fjFxoypki"
      },
      "source": [
        "## Markov Chain\n",
        "Let's say hi to reinforcement learning 🔥    \n",
        "Don't worry we just need to discover a tiny part of that which related to linear algebra.\n",
        "\n",
        "You can read about [Andrey markov](https://en.wikipedia.org/wiki/Andrey_Markov).    \n",
        "\n",
        "![Markov](data:image/jpeg;base64,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)\n",
        "\n",
        "Markov started out working in number theory but then got interested in probability. He enjoyed poetry and the great Russian poet Pushkin. Markov studied the sequence of letters found in the text of Eugene Onegin, in particular the sequence of consonants and vowels.\n",
        "\n",
        "He sought a way to describe patterns in sequences, such as text like Eugene Onegin. This eventually led to the idea of a system in which one transitions between states, and the probability of going to another state depends only on the current state.\n",
        "\n",
        "Hence, Markov pioneered the study of systems in which the future state of the system depends only on the present state in a random fashion. This has turned out to be a terrifically useful idea. For example, it is the starting point for analysis of the movement of stock prices, and the dynamics of animal populations.\n",
        "\n",
        "These have since been termed “Markov Chains.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e65d61fU0Edj"
      },
      "source": [
        "### Now what is Markov Chain?\n",
        "\n",
        "---\n",
        "A Markov chain is a mathematical model of a sequence of random events where the probability of each event depends only on the state of the system immediately before it. This means that the future state of the system depends only on the present state, and not on the past states. Markov chains are used to model a wide variety of phenomena, including the behavior of gamblers, the spread of disease, and the evolution of languages.    \n",
        "\n",
        "\n",
        "\n",
        "A [markov chain](https://en.wikipedia.org/wiki/Markov_chain) is a tuple $(S,P)$ :\n",
        "- $S \\rightarrow$ finite set of states\n",
        "- $P \\rightarrow$ is a transition probability matrix on $S$\n",
        "\n",
        "The transition probability matrix $P$ is a square matrix of size $|S| × |S|$, where $|S|$ is the number of states in $S$. The entry $P_{ij}$ in matrix $P$ represents the probability of transitioning from state $i$ to state $j$.     \n",
        "\n",
        "\n",
        "![Mar](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Markovkate_01.svg/260px-Markovkate_01.svg.png)\n",
        "\n",
        "**Properties of Markov Chains:**\n",
        "\n",
        "- **Markov property:**    \n",
        " The probability of a transition from state $i$ to state $j$ only depends on the **current** state $i$, and not on the past states of the system.\n",
        "\n",
        "- **Stationarity:**    \n",
        "The Markov chain has a stationary distribution if there exists a probability distribution $π$ on $S$ such that $π = πP$. The stationary distribution is a long-run equilibrium distribution of the Markov chain.\n",
        "\n",
        "- **Ergodicity:**    \n",
        "The Markov chain is ergodic if for every pair of states $i$ and $j$, there exists a positive integer n such that $P^n_{ij} > 0$. Ergodicity means that the Markov chain has a unique stationary distribution, and that the system will eventually converge to this distribution from any initial state.\n",
        "\n",
        "\n",
        "$$\\begin{align*}\n",
        "S &= \\text{Set of states} \\\\\n",
        "P &= \\text{Transition probability matrix} \\\\\n",
        "P_{ij} &= \\text{Probability of transitioning from state } i \\text{ to state } j \\\\\n",
        "\\pi &= \\text{Stationary distribution} \\\\\n",
        "P^n &= \\text{Product of the transition probability matrix P} \\\\\n",
        "\\pi P &= \\pi \\Longleftrightarrow \\pi \\text{ is stationary} \\\\\n",
        "\\text{ergodic} &= \\text{Markov chain will eventually converge to stationary distribution}\n",
        "\\end{align*}\n",
        "$$   \n",
        "Markov chains are essential tools in understanding, explaining, and predicting phenomena in computer science, physics, biology, economics, and finance.\n",
        "\n",
        "Now we will study an application of linear algebra. You will see how the concepts we use, such as vectors and matrices, get applied to a particular problem.\n",
        "\n",
        "> Many applications in computing are concerned with how a system behaves over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e29NyUo86a7M"
      },
      "source": [
        "\n",
        "Think of a Web server that is processing requests for Web pages, or network that is moving packets from place to place.We would like to describe how systems like these operate, and analyze them to understand their performance limits.     \n",
        "The way we model this is:    \n",
        "- we define some vector that describes the state of the system, and,   \n",
        "\n",
        "- we formulate a rule that tells us how to compute the next state of the system based on the current state of the system.\n",
        "\n",
        "So we would say that the state of the system at time $k$ is a vector $X_k \\in ℜ^n$ , and\n",
        "$$ x_{k+1}=T(X_k) \\; , for \\; time \\; k=0,1,2,...\\\\\n",
        "T: ℜ^n → \\Re ^n$$\n",
        "\n",
        "\n",
        "\n",
        "This situation is so common that it goes by many names:\n",
        "\n",
        "* In physics, this is called a __dynamical system__.  \n",
        "    * Here, $x_k$ might represent the position and velocity of a particle.\n",
        "    \n",
        "* When studying algorithms, this is called a __recurrence relation.__  \n",
        "    * Here, ${\\bf x_k}$ might represent the number of steps needed to solve a problem of size $k$.\n",
        "    \n",
        "* Most commonly, this is called a __difference equation.__\n",
        "    * The reason for this terminology is that it is a discrete analog of a differential equation in $k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-s7TwRc8X_b"
      },
      "source": [
        "The vector ${\\bf x_k}$ is called the state vector.     \n",
        "\n",
        "Of course, we are going to be particularly interested in the case where $T$ is a linear transformation.   \n",
        "\n",
        "Then we know that we can write the difference equation as:\n",
        "\n",
        "$$ {\\bf x_{k+1}} = A{\\bf x_k},$$\n",
        "\n",
        "where $A \\in \\mathbb{R}^{n\\times n}.$   \n",
        "\n",
        "This is a _linear difference equation._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKj15wV-ALFD"
      },
      "source": [
        "#### Exercise 4\n",
        "Tell us an example of markov-chain usage in real world problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hqxla-gAbfh"
      },
      "source": [
        "> Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My7gO71NAgLX"
      },
      "source": [
        "### **Population Problem**\n",
        "We are interested in the population of two regions, say the city and the suburbs.  \n",
        "\n",
        "Fix an initial year (say 2000) and let\n",
        "\n",
        "$$ {\\bf x_0} = \\left[\\begin{array}{cc}\\mbox{population of the city in 2000}\\\\\\mbox{population of the suburbs in 2000}\\end{array}\\right].$$\n",
        "\n",
        "Then\n",
        "\n",
        "$$ {\\bf x_1} = \\left[\\begin{array}{cc}\\mbox{population of the city in 2001}\\\\\\mbox{population of the suburbs in 2001}\\end{array}\\right],$$\n",
        "\n",
        "$${\\bf x_2} = \\left[\\begin{array}{cc}\\mbox{population of the city in 2002}\\\\\\mbox{population of the suburbs in 2002}\\end{array}\\right],$$\n",
        "\n",
        "$$\\dots \\mbox{etc.}$$\n",
        "\n",
        "\n",
        "We only concern ourselves with movements of people between the two regions.\n",
        "* no immigration, emigration, birth, death, etc.\n",
        "\n",
        "We assume that measurements have shown the following pattern:\n",
        "\n",
        "in any given year,\n",
        "\n",
        "* 5% of the people in the city move to the suburbs, and\n",
        "* 3% of the people in the suburbs move to the city.     \n",
        "\n",
        "You can think of this as:\n",
        "\n",
        "$$\\begin{array}{rcc}&\\mbox{From City}&\\mbox{From Suburbs}\\\\\\mbox{To City}& .95&.03\\\\\\mbox{To Suburbs}&.05&.97\\end{array}$$\n",
        "\n",
        "Then we can capture this update rule as a matrix:\n",
        "\n",
        "$$A = \\left[\\begin{array}{rr}.95&.03\\\\.05&.97\\end{array}\\right].$$\n",
        "\n",
        "We can see that this is correct by verifying that:\n",
        "\n",
        "$$\\left[\\begin{array}{cc}\\mbox{city pop. in 2001}\\\\\\mbox{suburb pop. in 2001}\\end{array}\\right] =\\left[\\begin{array}{rr}.95&.03\\\\.05&.97\\end{array}\\right] \\left[\\begin{array}{cc}\\mbox{city pop. in 2000}\\\\\\mbox{suburb pop. in 2000}\\end{array}\\right].$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS8a5zknBh5W"
      },
      "source": [
        "Let's look at $A$ again:\n",
        "\n",
        "$$A = \\left[\\begin{array}{rr}.95&.03\\\\.05&.97\\end{array}\\right].$$\n",
        "We note that $A$ has a special property: each of its columns adds up to 1.   \n",
        "\n",
        "Also, it would not make sense to have negative entries in $A$.   \n",
        "The reason that columns sum to 1 is that the total number of people in the system is not changing over time.   \n",
        "\n",
        "This leads to three definitions:     \n",
        "\n",
        "- **probability vector**:    \n",
        "is a vector of nonnegative entries that sums to 1.\n",
        "- **Stochastic matrix**:   \n",
        " is a square matrix of nonnegative values whose columns each sum to 1.  \n",
        "- **Markov chain**:    \n",
        " is a dynamical system whose state is a probability vector and which evolves according to a stochastic matrix.  \n",
        "\n",
        "That is, it is a probability vector ${\\bf x_0}$ and a stochastic matrix $A \\in \\mathbb{R}^{n\\times n}$ such that\n",
        "\n",
        "$${\\bf x_{k+1}} = A{\\bf x_k}\\;\\;\\;\\mbox{for}\\;k = 0,1,2,...$$\n",
        "\n",
        "So we think of a probability vector ${\\bf x_0}$ as describing how things are \"distributed\" across various categories -- the fraction of items that are in each category.     \n",
        "\n",
        "And we think of the stochastic matrix $A$\n",
        " as describing how things “redistribute” themselves at each time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu-gBqsZCw1x"
      },
      "source": [
        "### Exercise 4.2\n",
        "Suppose that in 2000 the population of the city is 600,000 and the population of the suburbs is 400,000.  What is the distribution of the population in:\n",
        " - 2001?  \n",
        " - 2002?\n",
        " - 2018?\n",
        " - 2024?\n",
        "\n",
        " > hint: $x_{k+1}=Ax_k , x_{k+2}=A(Ax_{k+1})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nHZ-1AfAGtW0",
        "outputId": "60a2092d-39b6-491d-be37-2598e6bcb3d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.417456 0.582544]\n"
          ]
        }
      ],
      "source": [
        "# Feel free to use any built-in function that you want\n",
        "\n",
        "# stochastic matrix\n",
        "np.array(\n",
        "    [[0.95,0.03],\n",
        "     [0.05,0.97]])\n",
        "\n",
        "np.array([0.60,0.40])\n",
        "\n",
        "# TODO\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Your final answer should be [0.417456 0.582544] for 2020\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuF_bKHJQcSB"
      },
      "source": [
        "### ***Predicting Distant Future***\n",
        "We noticed that the population of the city is going down. Will everyone eventually live in the suburbs?\n",
        "\n",
        "A important question about a Markov Chain is: what will happen in the distant future?\n",
        "\n",
        "For example, what happens to the population distribution in our example “in the long run?”\n",
        "\n",
        "Rather than answering that question right now, we’ll take a more interesting example.\n",
        "\n",
        "Suppose we have a system whose state transition is described by the stochastic matrix\n",
        "Suppose we have a system whose state transition is described by the stochastic matrix\n",
        "\n",
        "$$P = \\left[\\begin{array}{rrr}.5&.2&.3\\\\.3&.8&.3\\\\.2&0&.4\\end{array}\\right]$$\n",
        "\n",
        "and which starts int the state\n",
        "\n",
        "$${\\bf x_0} = \\left[\\begin{array}{r}1\\\\0\\\\0\\end{array}\\right].$$\n",
        "\n",
        "Consider the Markov Chain defined by $P$ and ${\\bf x_0}$, that is the chain defined as\n",
        "\n",
        "$${\\bf x_{k+1}} = P{\\bf x_k}\\;\\;\\;\\mbox{for}\\;k=0,1,2...$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2CCJcqbRDFy"
      },
      "source": [
        "### Exercise 4.3\n",
        "What happens to the system as time passes?\n",
        "Let's compute the state vectors ${\\bf x_1},\\dots,{\\bf x_{n}}$ to find out for n:\n",
        "- n=10\n",
        "- n=20\n",
        "- n=30\n",
        "- n=40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AhGK2NwQRKMQ",
        "outputId": "ef525db2-94d3-4671-b794-00e811808785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x(0) = [1 0 0]\n",
            "x(1) = [0.5 0.3 0.2]\n",
            "x(2) = [0.37 0.45 0.18]\n",
            "x(3) = [0.329 0.525 0.146]\n",
            "x(4) = [0.3133 0.5625 0.1242]\n",
            "x(5) = [0.30641 0.58125 0.11234]\n",
            "x(6) = [0.303157 0.590625 0.106218]\n",
            "x(7) = [0.3015689 0.5953125 0.1031186]\n",
            "x(8) = [0.30078253 0.59765625 0.10156122]\n",
            "x(9) = [0.30039088 0.59882813 0.10078099]\n",
            "x(10) = [0.30019536 0.59941406 0.10039057]\n",
            "x(11) = [0.30009767 0.59970703 0.1001953 ]\n",
            "x(12) = [0.30004883 0.59985352 0.10009765]\n",
            "x(13) = [0.30002441 0.59992676 0.10004883]\n",
            "x(14) = [0.30001221 0.59996338 0.10002441]\n",
            "x(15) = [0.3000061  0.59998169 0.10001221]\n",
            "x(16) = [0.30000305 0.59999084 0.1000061 ]\n",
            "x(17) = [0.30000153 0.59999542 0.10000305]\n",
            "x(18) = [0.30000076 0.59999771 0.10000153]\n",
            "x(19) = [0.30000038 0.59999886 0.10000076]\n",
            "x(20) = [0.30000019 0.59999943 0.10000038]\n",
            "x(21) = [0.3000001  0.59999971 0.10000019]\n",
            "x(22) = [0.30000005 0.59999986 0.1000001 ]\n",
            "x(23) = [0.30000002 0.59999993 0.10000005]\n",
            "x(24) = [0.30000001 0.59999996 0.10000002]\n",
            "x(25) = [0.30000001 0.59999998 0.10000001]\n",
            "x(26) = [0.3        0.59999999 0.10000001]\n",
            "x(27) = [0.3 0.6 0.1]\n",
            "x(28) = [0.3 0.6 0.1]\n",
            "x(29) = [0.3 0.6 0.1]\n",
            "x(30) = [0.3 0.6 0.1]\n",
            "x(31) = [0.3 0.6 0.1]\n"
          ]
        }
      ],
      "source": [
        "# stochastic matrix A\n",
        "n=32\n",
        "A = np.array(\n",
        "    [[.5,.2,.3],\n",
        "     [.3,.8,.3],\n",
        "     [.2, 0,.4]])\n",
        "# initial state vector\n",
        "x = np.array([1,0,0])\n",
        "\n",
        "# array to hold each future state vector\n",
        "xs = np.zeros((n,3))\n",
        "\n",
        "# compute future state vectors\n",
        "for i in range(n):\n",
        "    pass\n",
        "    # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "UAmsXe_4Sp9G",
        "outputId": "306c9a9a-a0bb-439c-fc95-590476a4f8e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#These plots show you what's going to happen after several steps:\n",
        "for i in range(3):\n",
        "    ax = plt.subplot(2, 2, i+1)\n",
        "    plt.plot(range(n), xs.T[i], 'o-')\n",
        "    ax.set_ylim([0, 1])\n",
        "    name=\"X_{}\".format(i+1)\n",
        "    plt.title(\"$\"+name+\"$\", size=12)\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L40bY0_ISMpw"
      },
      "source": [
        "### Exercise 4.4:\n",
        "Why the result gonna fix after a constant amount of step?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AA3CslZSb_S"
      },
      "source": [
        "> Your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMzx3CHBYMRU"
      },
      "source": [
        "Based on visual inspection, these vectors seem to be approaching\n",
        "\n",
        "$${\\bf q} = \\left[\\begin{array}{r}.3\\\\.6\\\\.1\\end{array}\\right].$$\n",
        "\n",
        "The components of ${\\bf x_k}$ don't seem to be changing much past about $k = 20.$\n",
        "\n",
        "In fact, we can confirm that the this system would be stable at $\\left[\\begin{array}{r}.3\\\\.6\\\\.1\\end{array}\\right]$ by noting that:\n",
        "\n",
        "$$\\left[\\begin{array}{rrr}.5&.2&.3\\\\.3&.8&.3\\\\.2&0&.4\\end{array}\\right]\\left[\\begin{array}{r}.3\\\\.6\\\\.1\\end{array}\\right] = \\left[\\begin{array}{r}.15+.12+.03\\\\.09+.48+.03\\\\.06+0+.04\\end{array}\\right] = \\left[\\begin{array}{r}.3\\\\.6\\\\.1\\end{array}\\right].$$\n",
        "\n",
        "This calculation is exact.  So it seems that:\n",
        "\n",
        "* the sequence of vectors is approaching $\\left[\\begin{array}{r}.3\\\\.6\\\\.1\\end{array}\\right]$ as a limit, and\n",
        "* when and if they get to that point, they will **stabilize** there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BwTW0J2YuEq"
      },
      "source": [
        "### Steady-State Vectors\n",
        "This convergence to a \"steady state\" is quite remarkable.  Is this a general phenomenon?\n",
        "**steady-state vector** :    \n",
        "If $P$ is a stochastic matrix, then a __steady-state vector__ (or __equilibrium vector__) for $P$ is a probability vector $\\bf q$  such that:\n",
        "\n",
        "$$P{\\bf q} = {\\bf q}.$$\n",
        "\n",
        "> It can be shown that __every stochastic matrix has at least one steady-state vector.__\n",
        "\n",
        "__Example.__\n",
        "\n",
        "$\\left[\\begin{array}{r}.3\\\\.6\\\\.1\\end{array}\\right]$ is the steady-state vector for $\\left[\\begin{array}{rrr}.5&.2&.3\\\\.3&.8&.3\\\\.2&0&.4\\end{array}\\right].$\n",
        "\n",
        "\n",
        "\n",
        "***Another Example:***\n",
        "The probability vector ${\\bf q} = \\left[\\begin{array}{r}.375\\\\.625\\end{array}\\right]$ is a steady-state vector for the population migration matrix $A$, because\n",
        "\n",
        "$$A{\\bf q} = \\left[\\begin{array}{rr}.95&.03\\\\.05&.97\\end{array}\\right]\\left[\\begin{array}{r}.375\\\\.625\\end{array}\\right] = \\left[\\begin{array}{r}.35625+.01875\\\\.01875+.60625\\end{array}\\right] = \\left[\\begin{array}{r}.375\\\\.625\\end{array}\\right] = {\\bf q}.$$\n",
        "\n",
        "To interpret this:\n",
        "\n",
        "* if the total population of the region is 1 million,\n",
        "* then if there are 375,000 persons in the city and 625,000 persons in the suburbs,\n",
        "* the populations of both the city and the suburbs would stabilize -- they would __stay the same in all future years.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGtUuxsAc6ti"
      },
      "source": [
        "### **Someone said Eigen value?**\n",
        "There is a strong connection between finding the **steady state** of a Markov chain and **eigen values** and eigen vectors. The steady state of a Markov chain is the long-term distribution of probabilities that the chain will be in each state. This distribution is important because it represents the long-run equilibrium of the system.  \n",
        "> The eigen values and eigen vectors of a Markov chain are closely related to the steady state.  \n",
        "\n",
        "Specifically, the eigen value 1 of the transition matrix corresponds to the steady state distribution of the Markov chain. This means that the steady state distribution is the eigen vector that corresponds to the eigen value 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeETQJV-do79"
      },
      "source": [
        "### Exercise 4.5:\n",
        "Find out the steady state vector of the transition matrix $P$ by using this procedure:\n",
        "- Calculate eigen values and eigen vectors\n",
        "- Find the eigen value corresponding to 1\n",
        "- Find the eigen vector corresponding to 1\n",
        "- Normalize the vector in the following manner:\n",
        "$$v_j=\\frac{v_j}{ \\sum^{n}_{i=0} v_i} $$\n",
        "\n",
        "- return that vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "duwEErvzZpah"
      },
      "outputs": [],
      "source": [
        "P = np.array([[0.5, 0.2, 0.3],\n",
        "               [0.3, 0.8, 0.3],\n",
        "               [0.2, 0, 0.4]])\n",
        "# Don't touch this :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HnMpYMpucICA",
        "outputId": "d227bdb4-83ca-4948-fb98-67a105b49760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.3 0.6 0.1]\n"
          ]
        }
      ],
      "source": [
        "# Remember you can use your function that implemented it before to find those\n",
        "# eigen values and eigen vectors.\n",
        "\n",
        "\n",
        "#TODO\n",
        "\n",
        "#Your result -> 0.3,0.6,0.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4lU3Sbonxcu"
      },
      "source": [
        "##### **Exercise 4.5.1**\n",
        "Implement that function using numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lH_-VnWogvlV",
        "outputId": "49ace6af-5a9a-4caa-e96d-d70199b46dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.  0.2 0.5] [[ 4.42325868e-01  7.07106781e-01  2.67261242e-01]\n",
            " [ 8.84651737e-01  5.42909769e-17 -8.01783726e-01]\n",
            " [ 1.47441956e-01 -7.07106781e-01  5.34522484e-01]]\n",
            "sdsd\n",
            "[0.44232587 0.88465174 0.14744196]\n",
            "[0.3 0.6 0.1]\n"
          ]
        }
      ],
      "source": [
        "# Use Numpy\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcnGlGTGn7e5"
      },
      "source": [
        "##### **Exercise 4.5.2**\n",
        "Implement that function using tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lfyNL8_Sgg65",
        "outputId": "f4267916-1397-4131-a21c-4658097951d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=complex128, numpy=array([0.3+0.j, 0.6+0.j, 0.1+0.j])>"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Use Tensorflow\n",
        "#TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgsCE9x0oXIu"
      },
      "source": [
        "> **At the end your result of all those three parts should be same and equal to $[0.3 , 0.6 , 0.1]$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rhSCLsjpOY5"
      },
      "source": [
        "#### Summary\n",
        "\n",
        "* Many phenomena can be describe using Markov's idea:\n",
        "    * There are \"states\", and\n",
        "    * Transition between states only depends on the current state.\n",
        "* Examples: population movement, jobs in a computer, consonants/vowels in a text...\n",
        "* Such a system can be expressed in terms of a stochastic matrix and a probability vector.\n",
        "* Evolution of the system in time is described by matrix multiplication.\n",
        "* Using linear algebraic tools we can predict the steady state of such a system!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq37uEjyrLUc"
      },
      "source": [
        "## Diagonalization\n",
        "Now Let's figure out the diagonalization procedure as we may need it further.    \n",
        "\n",
        "Diagonalization is the process of transforming a square matrix into a diagonal matrix. A diagonal matrix is a matrix in which all the off-diagonal elements are zero, and the diagonal elements are non-zero. Diagonalization is a powerful tool for solving linear systems, analyzing matrices, and understanding their properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg8K9ruXvM2G"
      },
      "source": [
        "### Exercise 4.6\n",
        "Let's diagonalize the earlier $P$ matrix that we've provided earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVoiWtKivtm3"
      },
      "source": [
        "#### Exercise 4.6.1\n",
        "Describe a complete procedure to realize how to diagonalize a matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXOd9M49wCpH"
      },
      "source": [
        "> Your answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQndVKIGwEUF"
      },
      "source": [
        "#### Exercise 4.6.2\n",
        "Is it true that all matrices are diagonalizable?\n",
        "say why or why not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZScD9TU5wS8Y"
      },
      "source": [
        "#### Exercise 4.6.3\n",
        "Now let's diagonalize\n",
        " in the following manner:\n",
        "- Calculate eigen values\n",
        "- Calculate eigen vectors\n",
        "- Create Eigen vector matrix\n",
        "- Inverse the eigen vector matrix\n",
        "- Diagonalize the matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mYZ9MimwdpU"
      },
      "source": [
        "##### Exercise 4.6.3.1\n",
        "Implement the procedure which came above using numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-3lcPB_0rf4b",
        "outputId": "ae730a1f-e848-421d-e75e-c6446a30d4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 3.00000000e-01  3.00000000e-01  3.00000000e-01]\n",
            " [ 7.67790359e-18 -2.55930120e-18 -7.67790359e-18]\n",
            " [ 2.00000000e-01 -1.33333333e-01  2.00000000e-01]]\n"
          ]
        }
      ],
      "source": [
        "# Create a matrix\n",
        "matrix = P\n",
        "\n",
        "#TODO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peSJyvoXw3Sj"
      },
      "source": [
        "##### Exercise 4.6.3.2\n",
        "Implement the procedure which came above using tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OscbPqfctoBB",
        "outputId": "5e064024-987f-45ce-871e-7579abf20fb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 2.9999983e-01+0.j  2.9999986e-01+0.j  2.9999995e-01+0.j]\n",
            " [ 1.6488167e-08+0.j -5.4960538e-09+0.j -1.6488160e-08+0.j]\n",
            " [ 2.0000000e-01+0.j -1.3333333e-01+0.j  2.0000002e-01+0.j]], shape=(3, 3), dtype=complex64)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Create a matrix\n",
        "matrix = tf.constant(P)\n",
        "\n",
        "\n",
        "\n",
        "#TODO\n",
        "\n",
        "\n",
        "# tf.matmul(eig_vecs * tf.linalg.diag(eig_vals), eig_vecs_inv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va9sB6XFxedQ"
      },
      "source": [
        "## Google Page Rank Algorithm\n",
        "One of the most sensational part of linear algebra is its tremendous impact on real-world problems.   \n",
        "In this section we're going to discover an ubelievable algorithm which has founded by Google Inc. in 1998.\n",
        "![Google](https://blog.hubspot.com/hs-fs/hubfs/image8-2.jpg?width=600&name=image8-2.jpg)\n",
        "\n",
        "Before we start,It's higly recommended to read the amazing\n",
        "[Paper](https://www.cis.upenn.edu/~mkearns/teaching/NetworkedLife/pagerank.pdf) of this algorithm which has published bu University of Pennsylvania.  (It should be mentioned the core patent behind this algorithm was first developed by Sergey Berin and Larry Page the Co-founders of Google in the University of Stanford)    \n",
        "![PB](https://media.wired.com/photos/5de6deca453df400086ddd80/master/pass/Biz-google-524309146.jpg)   \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctXSgpQi0ZQz"
      },
      "source": [
        "### **PageRank is what made Google so unique.**\n",
        "The World Wide Web starting becoming widely used in 1994.\n",
        "\n",
        "By 1998 the Web had become an indispensable information resource.\n",
        "\n",
        "However, the problem of effectively searching the Web for relevant information was not well addressed. A number of large search engines were available, with names that are now forgotten: Alta Vista, Lycos, Excite, and others.\n",
        "\n",
        "At present, most of them are no longer in existence, because Google emerged in 1998 and came to dominate Web search almost overnight.\n",
        "\n",
        "How did this happen?\n",
        "\n",
        "---\n",
        "\n",
        "As background: a typical search engine uses a two-step process to retrieve pages related to a user’s query.\n",
        "\n",
        "In the first step, basic text processing is done to find all documents that contain the query terms. Due to the massive size of the Web, this first step can result in many thousands of retrieved pages related to the query.\n",
        "\n",
        "Some of these pages are important, but most are not.\n",
        "\n",
        "The problem that Google solves better than the search engines of the mid 1990’s concerns the ordering in which the resulting search results are presented. This is the crucial factor in utility. A user wants to find the “correct” or “best” item at the top of the search results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnEzdVFR1CJO"
      },
      "source": [
        "### **The Insight**\n",
        "\n",
        "Around 1998, the limitations of standard search engines, which just used term frequency, we becoming apparent. A number of researchers were thinking about using additional sources of information to “rate” pages.\n",
        "\n",
        "The key idea that a number of researchers hit on was this: links are endorsements.\n",
        "\n",
        "When a first page contains a link to a second page, that is an indication that the author of the first page thinks the second page is worth looking at. If the first and second pages both contain the same query terms, it is likely that the second page is an important page with respect to that query term.\n",
        "\n",
        "---\n",
        "\n",
        "Consider a set of web pages, for a single query term (say “car manufacturers”) with this linking structure:\n",
        "\n",
        "![set](./1.jpg)\n",
        "\n",
        "\n",
        "It may be clear that the links between pages contain useful information. But what is the best way to extract that information in the form of rankings?\n",
        "\n",
        "Here is the strategy that Brin and Page used:    \n",
        "(From “The anatomy of a large-scale hypertextual Web search engine” (1998) published by Sergey Brin and Larry Page)   \n",
        "![Page](./2.png)\n",
        "\n",
        "We’ll study this algorithm, see how to implement it, and understand that what it is really about is **Markov Chains** and **eigenvectors**. 🔥🔥🔥\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0aKcQZc4AQD"
      },
      "source": [
        "### Random walks\n",
        "We start with the notion of a __random walk.__\n",
        "A random walk is a model of many sorts of processes that occur on graphs.\n",
        "\n",
        "Let us fix a graph $G$.  A random walk models the movement of an object on this graph.   \n",
        "We assume that the object moves from node to node in $G$, one move per time step $t.$  At time $t$ the object is at node $k$ (say) and at the next time $t+1$ it moves to another node chosen __at random__ from among the outgoing edges.\n",
        "For our initial discussion, we will assume that $G$ is the line graph:\n",
        "![3](./3.jpg)\n",
        "\n",
        "\n",
        "This is a graph in which each node is connected to two neighbors.  It's natural to identify the nodes with the integers $k = 1,\\dots,n.$\n",
        "\n",
        "An example application of this model would be a waiting line (or 'queue') like at a grocery store.  The current node corresponds to the number of people in the queue.   Given some number of people in the queue, only one of two things happens: either a person leaves the queue or a person joins the queue.   \n",
        "\n",
        "To complete the definition, what happens at the endpoints of the graph (nodes 1 and $n$) must be specified.     \n",
        "\n",
        "One possibility is for the walker to remain fixed at that location.   This is called a __random walk with absorbing boundaries.__\n",
        "\n",
        "Another possibility is for the walker to bounce back one unit when an endpoint is reached.   This is called a __random walk with reflecting boundaries.__\n",
        "\n",
        "\n",
        "We can also set a particular probability $1-p$ of moving \"to the right\" (from $k$ to $k+1$) and $p$ of moving \"to the left\" (from $k$ to $k-1$).\n",
        "\n",
        "> ## ***We can capture the process of movement on $G$ as a Markov chain.***  \n",
        "\n",
        "\n",
        "\n",
        "The way to interpret the steady-state of the Markov chain in terms of the random walk is:\n",
        "\n",
        "Let the chain (random walk) start in the given state.  At some long time in the future, make an observation of the state that the chain is in.   Then the steady-state distribution gives, for each state, the probability that the chain is in that state when we make our observation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiOD6nXU7Ji0"
      },
      "source": [
        "### Absorbing Bounderies\n",
        "A random walk on $\\{0,1,2,3,4\\}$ with absorbing boundaries has a transition matrix of\n",
        "\n",
        "$$P=\\begin{bmatrix}1&p&0&0&0\\\\0&0&p&0&0\\\\0&1-p&0&p&0\\\\0&0&1-p&0&0\\\\0&0&0&1-p&1\\end{bmatrix}$$   \n",
        "(based on a graph that we provided earlier)\n",
        "\n",
        "Now Let's have this scenario:   \n",
        "\n",
        "Consider a very simple casino game.  A gambler (with some money to lose) flips a coin and calls heads or tails.  If the gambler is correct, she wins a dollar.  If she is wrong, she loses a dollar.  The gambler will quit the game when she has either won $n-1$ dollars or lost all of her money.\n",
        "\n",
        "Suppose that $n=5$ and the gambler starts with \\$2.  The gambler's winnings must move up or down one dollar with each coin flip, and once the gambler's winnings reach 0 or 4, they do not change any more since the gambler has quit the game.  \n",
        "\n",
        "Such a process may be modeled as a random walk on $\\{0,1,2,3,4\\}$ with absorbing boundaries.   Since a move up or down is equally likely in this case, $p = 1/2$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc5G6TpI8RLq"
      },
      "source": [
        "### Exercise 5.1\n",
        "The transition matrix is not regular. why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZeoc3_n8X_t"
      },
      "source": [
        "> Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hh9BjbP8dEr"
      },
      "source": [
        "### Exercise 5.2\n",
        "Why there is no unique steady state?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hv4QSyR48jPd"
      },
      "source": [
        "> Your answer here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9bg_E25856y"
      },
      "source": [
        "### Exercise 5.3\n",
        "Now Let's consider $p=0.45$   \n",
        "findout the probability that the gambler will lose all her money."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRVuY1H_9pHj"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "iteration=100\n",
        "p = 0.45\n",
        "A = np.array([[1,p,0,0,0],[0,0,p,0,0],[0,1-p,0,p,0],[0,0,1-p,0,0],[0,0,0,1-p,1]])\n",
        "B = A.copy()\n",
        "for i in range(100):\n",
        "  pass\n",
        "  #TODO\n",
        "print(B @ np.array([0,0,1,0,0]))\n",
        "\n",
        "#Your answer should be near to 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-9PcSso_BGf"
      },
      "source": [
        "### Random walks on undirected graph\n",
        "Now let's consider a random walk on a more interesting graph:       \n",
        "\n",
        "![4](./4.jpg)       \n",
        "\n",
        "This graph is undirected – each edge can be followed in either direction.\n",
        "\n",
        "Again, at each node there is an equal probability of departing to any adjacent node.\n",
        "\n",
        "The transition matrix associated with a random walk on this graph is\n",
        "\n",
        "$$P = \\begin{bmatrix}\n",
        "0&1/3&1/4&0&0&0&0\\\\\n",
        "1/2&0&1/4&0&1/2&0&0\\\\\n",
        "1/2&1/3&0&1&0&1/3&0\\\\\n",
        "0&0&1/4&0&0&0&0\\\\\n",
        "0&1/3&0&0&0&1/3&0\\\\\n",
        "0&0&1/4&0&1/2&0&1\\\\\n",
        "0&0&0&0&0&1/3&0\\end{bmatrix}$$\n",
        "\n",
        "It turns out that this matrix is regular ($P^3$ has no zero entries.)\n",
        "\n",
        "Hence, the associated Markov Chain converges to a single steady state.  (It has only one eigenvalue of 1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBERfK0e_orV"
      },
      "source": [
        "### Exercise 5.4\n",
        "find out the corresponding eigen vector of this transition matrix.\n",
        "and calculate the steady state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KMSQh1xu_07K",
        "outputId": "6146e71b-52cf-469a-d0cf-221bfff998de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.01007563 3.01511345 4.02015126 1.00503782 2.01007563 3.01511345\n",
            " 1.00503782]\n"
          ]
        }
      ],
      "source": [
        "A = np.array([\n",
        "[   0, 1./3, 1./4, 0,    0,    0, 0],\n",
        "[1./2,    0, 1./4, 0, 1./2,    0, 0],\n",
        "[1./2, 1./3,    0, 1,    0, 1./3, 0],\n",
        "[   0,    0, 1./4, 0,    0,    0, 0],\n",
        "[   0, 1./3,    0, 0,    0, 1./3, 0],\n",
        "[   0,    0, 1./4, 0, 1./2,    0, 1],\n",
        "[   0,    0,    0, 0,    0, 1./3, 0]])\n",
        "\n",
        "\n",
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjPs7JfK_9m0"
      },
      "source": [
        "The eigenvector corresponding to the eigenvalue of 1 is the steady-state of the Markov Chain.\n",
        "\n",
        "If you've calculated successfuly, we can find that the steady-state is $\\begin{bmatrix}2\\\\3\\\\4\\\\1\\\\2\\\\3\\\\1\\end{bmatrix}/16.$    \n",
        "\n",
        "That is, the probability of bring in node 1 at steady state is 2/16;  the probability of being in node 2 is 3/16;  the probability of being in node 3 is 4/16, etc.    \n",
        "\n",
        "If you look at the probailities of being in each node, you'll realize the connection between the **degree of nodes and and the probabilty**.\n",
        "\n",
        "This is not a coincidence!  \n",
        "\n",
        "In fact it can be __proved__ that the steady-state distribution of a random walk on an undirected graph is proportional to node degree.\n",
        "\n",
        "That is, the probability of being at a particular node at steady state is proportional to that node's degree.\n",
        "\n",
        "> This is really amazing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd4oW6WgBUE1"
      },
      "source": [
        "### **Someone said directed graph?!**\n",
        "More interesting behavior arises when we walk randomly on a __directed__ graph.  \n",
        "\n",
        "In this graph, all edges are \"one-way streets\" -- nodes are joined not by lines but by arrows.   The chain can move from vertex to vertex, but only in the directions allowed by the arrows.\n",
        "\n",
        "An example of a directed graph is:    \n",
        "\n",
        "![5](./5.jpg)      \n",
        "\n",
        "The transition matrix for this graph is:\n",
        "\n",
        "$$P = \\begin{bmatrix}\n",
        "0&0&1/3&0&0&0\\\\\n",
        "1/2&0&1/3&0&0&0\\\\\n",
        "1/2&0&0&0&0&0\\\\\n",
        "0&0&0&0&1/2&1\\\\\n",
        "0&0&1/3&1/2&0&0\\\\\n",
        "0&0&0&1/2&1/2&0\n",
        "\\end{bmatrix}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwy0WCzpB_G8"
      },
      "source": [
        "### Exercise 5.5\n",
        "Why this matrix is not regular and we can find an specific steady state?    \n",
        "(Any power of $P$\n",
        " will preserve this column of zeros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D30DU3E7CJN7"
      },
      "source": [
        "> Your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEkXtuUMCl7b"
      },
      "source": [
        "### Structure of the Internet\n",
        "There are many ways to use link structure to infer which pages are most important.\n",
        "\n",
        "There was a lot of experimentation in the late 1990s with various methods.\n",
        "\n",
        "Here are some examples of link structures found in the Web:\n",
        "![Web](https://www.cs.bu.edu/fac/crovella/cs132-book/_images/L19PageRank_65_0.png)\n",
        "\n",
        "Why did Page and Brin settle on the **random walk** as the basis for their approach?\n",
        "\n",
        "In fact, the intuiution they started from was simpler:\n",
        "\n",
        "<center><font color = \"yellow\"><b>a page is 'important' if many 'important' pages link to it.</font> </center>\n",
        "\n",
        "More precisely, this definition of 'importance' is:\n",
        "\n",
        "$$\\mbox{Importance of page $k$} = \\sum_j \\mbox{(Importance of page $j$)}\\cdot\\mbox{(Probability of going from page $j$ to page $k$.)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaQKddhCDmtl"
      },
      "source": [
        "This is a very intuitive definition of importance.   \n",
        "\n",
        "There is a bit of a issue however -- it is self-referential!\n",
        "\n",
        "The 'importance' of a page appears on both sides of the equation.\n",
        "\n",
        "How can we solve this equation to get a fixed 'importance' for a given page?\n",
        "\n",
        "**Answering this question is where the random walk comes in.**\n",
        "\n",
        "What Page and Brin observed was that this equation\n",
        "\n",
        "$$\\mbox{Importance of page $k$} = \\sum_j \\mbox{(Importance of page $j$)}\\cdot\\mbox{(Probability of going from page $j$ to page $k$.)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2rTIB17ECjq"
      },
      "source": [
        "### The Real Ones!\n",
        "Sergey Berin and Larry Pages were couple of engineers who have totally shocked the world.\n",
        "There is a sentimental intution mapping between this idea and markov chain and that is:\n",
        "$$ x= Px$$\n",
        "$x \\rightarrow \\textbf{‘importance’ of all pages}$\n",
        "\n",
        "$P \\rightarrow \\textbf{‘probability of going from page $j$ to page $k$ ' in the stochastic matrix $P$}$\n",
        "\n",
        "Now we understand what they mean:\n",
        "> PageRank can be thought of as a model of user behavior. We assume there is a “random surfer” who is given a web page at random and keeps clicking on links, never hitting “back” but eventually gets bored and starts on another random page. The probability that the random surfer visits a page is its PageRank.\n",
        "\n",
        "What they are implying is that a random surfer should visit important pages more often and unimportant pages less often."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEFAZYw2FS2E"
      },
      "source": [
        "The way to interpret this precisely is:\n",
        "\n",
        "1- Form the graph that encodes the connections between Web pages that are retrieved for a particular query.    \n",
        "\n",
        "2- Construct a Markov chain that corresponds to a random walk on this graph.   \n",
        "\n",
        "3- Rank-order the pages according to their probability in the Markov chain's steady state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0rEunlEFxeR"
      },
      "source": [
        "### Let's do it!(Step 1)\n",
        "\n",
        "Now lets assume a set of webpages have been conected to each other like a directed graph that was provided earlier.\n",
        "\n",
        "It doesn't have any unique steady-state for the specific transition matrix.(you can check it your self if you need)\n",
        "\n",
        "We have already seen the transition matrix for this graph:\n",
        "\n",
        "$$P = \\begin{bmatrix}\n",
        "0&0&1/3&0&0&0\\\\\n",
        "1/2&0&1/3&0&0&0\\\\\n",
        "1/2&0&0&0&0&0\\\\\n",
        "0&0&0&0&1/2&1\\\\\n",
        "0&0&1/3&1/2&0&0\\\\\n",
        "0&0&0&1/2&1/2&0\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "We have observed that this transition matrix is __not__ regular, because for any $A^k, k>0,$ the second column will  be zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hkNsSPlH-OX"
      },
      "source": [
        "The reason that column 2 of $P$ is zero is that the Web page corresponding to node 2 has no links embedded in it, so there is nowhere to go from this page.   Of course this will happen a lot in an arbitrary collection of Web pages.\n",
        "\n",
        "Note that Page and Brin say that the random surfer will occasionally \"start on another random page.\"   In other words, it seems reasonable that when reaching a page with no embedded links, the surfer chooses another page at random.\n",
        "\n",
        "So this motivates the first adjustment to $P$:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8tZQ9F4IImT"
      },
      "source": [
        "### Step 2.\n",
        "\n",
        "Form the matrix $P'$ as follows:  for each column in $P$ that is entirely zeros, replace it with a column in which each entry is $1/n$.\n",
        "\n",
        "In our example:\n",
        "\n",
        "$$P = \\begin{bmatrix}\n",
        "0&0&1/3&0&0&0\\\\\n",
        "1/2&0&1/3&0&0&0\\\\\n",
        "1/2&0&0&0&0&0\\\\\n",
        "0&0&0&0&1/2&1\\\\\n",
        "0&0&1/3&1/2&0&0\\\\\n",
        "0&0&0&1/2&1/2&0\n",
        "\\end{bmatrix} \\;\\;{\\rightarrow}\\;\\;\n",
        "P' = \\begin{bmatrix}\n",
        "0&1/n&1/3&0&0&0\\\\\n",
        "1/2&1/n&1/3&0&0&0\\\\\n",
        "1/2&1/n&0&0&0&0\\\\\n",
        "0&1/n&0&0&1/2&1\\\\\n",
        "0&1/n&1/3&1/2&0&0\\\\\n",
        "0&1/n&0&1/2&1/2&0\n",
        "\\end{bmatrix}\\;\\;=\\;\\;\n",
        " \\begin{bmatrix}\n",
        "0&1/6&1/3&0&0&0\\\\\n",
        "1/2&1/6&1/3&0&0&0\\\\\n",
        "1/2&1/6&0&0&0&0\\\\\n",
        "0&1/6&0&0&1/2&1\\\\\n",
        "0&1/6&1/3&1/2&0&0\\\\\n",
        "0&1/6&0&1/2&1/2&0\n",
        "\\end{bmatrix}$$\n",
        "\n",
        "In other words, for an arbitrary set of web pages, there is no guarantee that their transition matrix will be regular.\n",
        "\n",
        "Once again, let’s read the words of Page and Brin closely: the surfer “eventually gets bored and starts on another random page.”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upbenAyPImvP"
      },
      "source": [
        "### Step 3.\n",
        "\n",
        "In practice this means that there a small probability that the surfer will jump from any page to any other page at random.\n",
        "\n",
        "Let's call this small probability $\\alpha.$\n",
        "\n",
        "We can't just add $\\alpha$ to every entry in $P'$, because then the columns of the new matrix would not sum to 1.    \n",
        "\n",
        "\n",
        "Instead we decrease each entry in $P'$ by a factor of $(1-\\alpha)$, and then add ${\\alpha}/{n}$ to it.\n",
        "\n",
        "So we compute the final transition matrix $P''$ as:\n",
        "\n",
        "$$P''_{ij} = (1-\\alpha)P'_{ij} + \\frac{\\alpha}{n}.$$\n",
        "\n",
        "We can write this as a matrix equation:\n",
        "\n",
        "$$P'' = (1-\\alpha)P' + \\frac{\\alpha}{n} \\mathbf{1}$$\n",
        "\n",
        "where $\\mathbf{1}$ is an $n\\times n$ matrix of 1's.\n",
        "\n",
        "In our example, let's say that $\\alpha = 1/10$ (in reality it would be smaller).  So $\\alpha/n = 1/60.$\n",
        "\n",
        "Then:\n",
        "\n",
        "$$ P' \\begin{bmatrix}\n",
        "0&1/6&1/3&0&0&0\\\\\n",
        "1/2&1/6&1/3&0&0&0\\\\\n",
        "1/2&1/6&0&0&0&0\\\\\n",
        "0&1/6&0&0&1/2&1\\\\\n",
        "0&1/6&1/3&1/2&0&0\\\\\n",
        "0&1/6&0&1/2&1/2&0\n",
        "\\end{bmatrix} \\;\\;{\\rightarrow}\\;\\; P'' = \\begin{bmatrix}\n",
        "1/60&1/6&19/60&1/60&1/60&1/60\\\\\n",
        "7/15&1/6&19/60&1/60&1/60&1/60\\\\\n",
        "7/15&1/6&1/60&1/60&1/60&1/60\\\\\n",
        "1/60&1/6&1/60&1/60&7/15&11/12\\\\\n",
        "1/60&1/6&19/60&7/15&1/60&1/60\\\\\n",
        "1/60&1/6&1/60&7/15&7/15&1/60\n",
        "\\end{bmatrix}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tpw9UeIJJX6"
      },
      "source": [
        "### Exercise 5.6\n",
        "Why the $P^{''}$ is regular?\n",
        "\n",
        "> ## **$P''$ is the Markov Chain that Brin and Page defined, and which is used by PageRank to rank pages in response to a Google search.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRKCFmFgJSUo"
      },
      "source": [
        "> your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x0w89vTKA0X"
      },
      "source": [
        "### **It's show time** 🔥\n",
        "Let's find the ranking of those websites graph that we've provided earlier.\n",
        "### Exercise 5.7\n",
        "Now we want to calculate the Steady-state of our matrix P in the following manner:\n",
        "- Calculte $P^{'}$\n",
        "- Implement $\\alpha$ formula\n",
        "- Calculate $p^{''}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cejZTiKPK0g1",
        "outputId": "5ddf9fa6-ec5d-4ffd-cf32-0c10a7e39695"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6, 6)"
            ]
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "the_P = np.array([\n",
        "[0,0, 1./3,0,0,0],\n",
        "[1./2,0,1./3,0,0,0],\n",
        "[1./2,0,0,0,0,0],\n",
        "[0,0,0,0,1./2.,1],\n",
        "[0,0,1./3.,1./2., 0, 0],\n",
        "[0,0,0, 1./2,1.2, 0]])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#TODO : find p\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI4F68vjNXmx"
      },
      "source": [
        "### Exercise 5.8\n",
        "Calculate the steady-state vector of the $P^{\"} matrix$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "sLomYXiTM8DI"
      },
      "outputs": [],
      "source": [
        "# If you've calculated it correctly, the P\" should be:\n",
        "\n",
        "P = np.array([\n",
        "[1./60, 1./6, 19./60, 1./60, 1./60,  1./60],\n",
        "[7./15, 1./6, 19./60, 1./60, 1./60,  1./60],\n",
        "[7./15, 1./6,  1./60, 1./60, 1./60,  1./60],\n",
        "[1./60, 1./6,  1./60, 1./60, 7./15, 11./12],\n",
        "[1./60, 1./6, 19./60, 7./15, 1./60,  1./60],\n",
        "[1./60, 1./6,  1./60, 7./15, 7./15,  1./60]\n",
        "])\n",
        "\n",
        "#TODO\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBiF7OyuORb0"
      },
      "source": [
        "### Exercise 5.9\n",
        "Extract the corresponding eigenvector relate to $\\lambda=1$\n",
        "from the list of eigen vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "S4zA5avFPEsB"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHf4QbKXP6Hh"
      },
      "source": [
        "### Exercis 5.10\n",
        "- Normalize the eigen vector in the manner which came before\n",
        "- return the steady state\n",
        "- the result should be similar to the matrix below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_x2iI3nQPSr"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Mb34U9OJks"
      },
      "source": [
        "\n",
        "$\\mathbf{S.state} = \\begin{bmatrix}0.037\\\\0.054\\\\0.041\\\\0.375\\\\0.206\\\\0.286\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ervg72iQRAf"
      },
      "source": [
        "## **Final Exercise**\n",
        "Sort the s.state in a descending way to extract the final order of page ranking that google should provide.\n",
        "\n",
        "> # **result: [4,6,5,2,3,1]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F55q1BRTbapk",
        "outputId": "3505e1aa-097c-42af-e756-7d7a5207e9e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final order = [4 6 5 2 3 1]\n",
            "importance = [0.37508082 0.28624589 0.20599833 0.05395735 0.04150565 0.03721197]\n"
          ]
        }
      ],
      "source": [
        "#TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvD5OZFERUKU"
      },
      "source": [
        "# And ...\n",
        "    That's it!\n",
        "    I hope that you've enjoyed.\n",
        "    Wish you nothing but the best and\n",
        "\n",
        "<center><h1><font color=\"#bcf20a\"><b>Good Luck :)</font> </center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW6es2gpRK6T"
      },
      "source": [
        "> This document was compiled, gathered and coded by the teaching assistant team and may be used only for educational purposes. The authors would like to thank the many projects and educational material that made their source code freely available on the internet, especially otter-grader that made the generation and sanitization of the notebook easier."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
